{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 6: Model-based Collaborative Filtering for **Ranking** Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we still do Collaborative Filtering and Matrix Factorization in this unit, we do something fundamentally different: we change from rating prediction to **ranking prediction**.\n",
    "\n",
    "We achieve this by changing the optimization criterion. Instead of minimizing the deviation between true and predicted ratings we push positive and negative user-item combinationa as much as possible apart. We transform explicit user feedback into implicit feedback. Implicit feedback refers to user interaction without the purpose to reflect preference or disregard and is much more common in pactice. Ranking prediction algorithms tackle to learn from implicit feedback data.\n",
    "\n",
    "In addition, ranking-based algorithms yield a much more intuitive prediction result. Our goal is to present to the user a very limited amount of items in the correct ordering. Therefore, ordering is much more important than rating prediction. Ranking-based algorithms like BPR work pair-wise, i.e. for a user and two items they yield the correct order of both items for the user. Generalizing from this, we can impose an ordering on our item corpus and pick the top-$N$ to present to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys_training.data import Dataset\n",
    "from recsys_training.evaluation import get_relevant_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml100k_ratings_filepath = '../data/raw/ml-100k/u.data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different to previous units, we work with implicit feedback data now. However, MovieLens is an explicit feedback dataset, we can argue that everything above the user mean ratings is positive and everything below is negative. Bayesian Personalized Ranking learns from implicit positive feedback data and randomly samples negative feedback data during training. Thus, we keep all ratings above a threhold of $4.0$ and remove all other ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(ml100k_ratings_filepath)\n",
    "data.filter(min_rating=4.0)\n",
    "data.rating_split(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want to learn the user/item latent factors from rating data, we first randomly initialize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "m = data.n_users\n",
    "n = data.n_items\n",
    "d = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Factor initialization\n",
    "random_state = np.random.RandomState(seed)\n",
    "user_factors = (random_state.rand(m, d) - 0.5) / d\n",
    "item_factors = (random_state.rand(n, d) - 0.5) / d\n",
    "        \n",
    "ratings = data.train_ratings.sample(frac=1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive implicit feedback items\n",
    "user_pos_items = {}\n",
    "# corpus of all remaining items for every user\n",
    "# Ask me about the \"Non missing at random hypothesis\" ;)\n",
    "user_neg_items = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = ratings[['user', 'item']].groupby('user')\n",
    "groups = grouped.groups.keys()\n",
    "for user in data.users:\n",
    "    pos_items = []\n",
    "    if user in groups:\n",
    "        pos_items = grouped.get_group(user).item.values\n",
    "    neg_items = np.setdiff1d(data.items, pos_items)\n",
    "    user_pos_items[user] = pos_items\n",
    "    user_neg_items[user] = neg_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, there is some math involved:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{x}_{uij} = \\hat{x}_{ui} - \\hat{x}_{uj} \\\\\n",
    "x_{ui} = \\sum_{f=1}^{d} w_{uf} \\cdot h_{if}, i \\in I_u^+ \\\\\n",
    "x_{uj} = \\sum_{f=1}^{d} w_{uf} \\cdot h_{jf}, j \\in I_u^- \\\\\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{BPR-Opt} := \\sum_{(u,i,j) \\in D_S} ln(\\hat{x}_{uijj}) - \\lambda_{\\Theta} \\cdot ||\\Theta||^2\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial \\text{BPR-Opt}}{\\partial \\Theta} = \\frac{-e^{-\\hat{x}_{uij}}}{1+e^{-\\hat{x}_{uij}}} \\cdot \\frac{\\partial \\hat{x}_{uij}}{\\partial \\Theta} - \\lambda_{\\Theta} \\cdot \\Theta\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial x_{uij}}{\\partial \\Theta} =\n",
    "\\begin{cases}\n",
    "(h_{if}-h_{jf}) & \\text{for } \\Theta = w_{uf} \\\\\n",
    "w_{uf} & \\text{for } \\Theta = h_{if} \\\\\n",
    "-w_{uf} & \\text{for } \\Theta = h_{jf}\n",
    "\\end{cases}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about regularization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampling(user: int, user_neg_items) -> int:\n",
    "    \"\"\"\n",
    "    Return the item ids for negative samples\n",
    "    \"\"\"\n",
    "    # TODO: Allow for popularity-based pdf for choosing negative item\n",
    "\n",
    "    return np.random.choice(user_neg_items[user])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Adapt the `compute_gradients` method from the unit before to realize stochastic gradient descent (SGD) for Bayesian Personalized Ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(user_embed: np.array,\n",
    "                      pos_item_embed: np.array,\n",
    "                      neg_item_embed: np.array,\n",
    "                      l2_decay: Dict[str, float]) -> Tuple[np.array, np.array, np.array]:\n",
    "    \n",
    "    pos_pred = np.sum(user_embed * pos_item_embed)\n",
    "    neg_pred = np.sum(user_embed * neg_item_embed)\n",
    "    pred = pos_pred - neg_pred\n",
    "\n",
    "    generic_grad = (-np.exp(-pred) * sigmoid(pred))\n",
    "\n",
    "    user_grad = generic_grad * (pos_item_embed - neg_item_embed)\n",
    "    pos_item_grad = generic_grad * user_embed\n",
    "    neg_item_grad = generic_grad * (-user_embed)\n",
    "\n",
    "    user_grad += user_embed * l2_decay['user']\n",
    "    pos_item_grad += pos_item_embed * l2_decay['pos']\n",
    "    neg_item_grad += neg_item_embed * l2_decay['neg']\n",
    "\n",
    "    return user_grad, pos_item_grad, neg_item_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_update(epoch: int, samples: np.array) -> float:\n",
    "    # take the 1000 most recent ratings and compute the mean ranking loss\n",
    "    users = samples[:, 0]\n",
    "    pos_items = samples[:, 1]\n",
    "    neg_items = np.array([negative_sampling(user, user_neg_items)\n",
    "                          for user in users])\n",
    "\n",
    "    user_embeds = user_factors[users - 1]\n",
    "    pos_item_embeds = item_factors[pos_items - 1]\n",
    "    neg_item_embeds = item_factors[neg_items - 1]\n",
    "\n",
    "    pos_preds = np.sum(user_embeds * pos_item_embeds, axis=1)\n",
    "    neg_preds = np.sum(user_embeds * neg_item_embeds, axis=1)\n",
    "    preds = pos_preds - neg_preds\n",
    "\n",
    "    loss = -np.log(sigmoid(preds)).mean()\n",
    "    print(f\"Epoch {epoch+1:02d}: Mean Ranking Loss: {loss:.4f}\")\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of minibatch gradient descent we do stochastic gradient descent here. It just shrinks the batch size down to 1 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "learning_rate = 0.05\n",
    "l2_decay = {'user': 0.0, 'pos': 0.0, 'neg': 0.0}\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Mean Ranking Loss: 0.6927\n",
      "Epoch 02: Mean Ranking Loss: 0.6823\n",
      "Epoch 03: Mean Ranking Loss: 0.4938\n",
      "Epoch 04: Mean Ranking Loss: 0.3456\n",
      "Epoch 05: Mean Ranking Loss: 0.3330\n",
      "Epoch 06: Mean Ranking Loss: 0.2850\n",
      "Epoch 07: Mean Ranking Loss: 0.2882\n",
      "Epoch 08: Mean Ranking Loss: 0.2847\n",
      "Epoch 09: Mean Ranking Loss: 0.2564\n",
      "Epoch 10: Mean Ranking Loss: 0.2478\n",
      "Epoch 11: Mean Ranking Loss: 0.2349\n",
      "Epoch 12: Mean Ranking Loss: 0.2252\n",
      "Epoch 13: Mean Ranking Loss: 0.1880\n",
      "Epoch 14: Mean Ranking Loss: 0.1932\n",
      "Epoch 15: Mean Ranking Loss: 0.1863\n",
      "Epoch 16: Mean Ranking Loss: 0.1861\n",
      "Epoch 17: Mean Ranking Loss: 0.1913\n",
      "Epoch 18: Mean Ranking Loss: 0.1769\n",
      "Epoch 19: Mean Ranking Loss: 0.1637\n",
      "Epoch 20: Mean Ranking Loss: 0.1724\n",
      "Epoch 21: Mean Ranking Loss: 0.1897\n",
      "Epoch 22: Mean Ranking Loss: 0.1736\n",
      "Epoch 23: Mean Ranking Loss: 0.1514\n",
      "Epoch 24: Mean Ranking Loss: 0.1333\n",
      "Epoch 25: Mean Ranking Loss: 0.1447\n",
      "Epoch 26: Mean Ranking Loss: 0.1392\n",
      "Epoch 27: Mean Ranking Loss: 0.1448\n",
      "Epoch 28: Mean Ranking Loss: 0.1563\n",
      "Epoch 29: Mean Ranking Loss: 0.1494\n",
      "Epoch 30: Mean Ranking Loss: 0.1369\n"
     ]
    }
   ],
   "source": [
    "ratings_arr = ratings[['user', 'item']].values\n",
    "n_ratings = len(ratings_arr)\n",
    "loss_trace = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for _ in range(len(ratings)):\n",
    "        random_index = np.random.randint(n_ratings)\n",
    "        user, pos_item = tuple(ratings_arr[random_index])\n",
    "        neg_item = negative_sampling(user, user_neg_items)\n",
    "\n",
    "        # TODO: Align indices by making mapping user ids to compact and 0-indexed space\n",
    "        # Deduct 1 as user ids are 1-indexed, but array is 0-indexed\n",
    "        user_embed = user_factors[user - 1]\n",
    "        pos_item_embed = item_factors[pos_item - 1]\n",
    "        neg_item_embed = item_factors[neg_item - 1]\n",
    "\n",
    "        user_grad, pos_item_grad, neg_item_grad = \\\n",
    "            compute_gradients(user_embed,\n",
    "                              pos_item_embed,\n",
    "                              neg_item_embed,\n",
    "                              l2_decay)\n",
    "\n",
    "        # update\n",
    "        # TODO: Correct accordingly here and in Multi-Channel BPR Repo\n",
    "        # update fails for multiple same users or items within a batch\n",
    "        user_factors[user - 1] -= learning_rate * user_grad\n",
    "        item_factors[pos_item - 1] -= learning_rate * pos_item_grad\n",
    "        item_factors[neg_item - 1] -= learning_rate * neg_item_grad\n",
    "\n",
    "    if verbose:\n",
    "        samples = ratings_arr[-1000:]\n",
    "        loss = print_update(epoch, samples)\n",
    "        loss_trace.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(epochs), loss_trace, 'b--')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model for Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created a model to describe users and items in terms of latent vectors. But this time we fitted them to get the rankings correctly. So for obtaining recommendations we simply multiply user-item latent vectors we are interested in and achieve an estimate that can be used to order items for a given user. This time it is not a rating prediction, but still a prediction.\n",
    "\n",
    "For that, we can reuse the `get_prediction` method from previous units.\n",
    "\n",
    "Thus, before writing the `get_recommendations` again we first implement `get_prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(user: int, items: np.array = None, remove_known_pos: bool = True) -> Dict[int, Dict[str, float]]:\n",
    "    if items is None:\n",
    "        if remove_known_pos:\n",
    "            # Predict from unobserved items\n",
    "            # We simplified this compared to the unit before\n",
    "            items = user_neg_items[user]\n",
    "        else:\n",
    "            items = np.array(data.items)\n",
    "    if type(items) == np.int64:\n",
    "        items = np.array([items])\n",
    "    \n",
    "    user_embed = user_factors[user - 1].reshape(1, -1)\n",
    "    item_embeds = item_factors[items - 1].reshape(len(items), -1)\n",
    "\n",
    "    # use array-broadcasting\n",
    "    preds = np.sum(user_embed * item_embeds, axis=1)\n",
    "    sorting = np.argsort(preds)[::-1]\n",
    "    preds = {item: {'pred': pred} for item, pred in\n",
    "             zip(items[sorting], preds[sorting])}\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_predictions = get_prediction(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, {'pred': 6.6614164520522605}),\n",
       " (475, {'pred': 6.346045655925021}),\n",
       " (98, {'pred': 6.023031945636602}),\n",
       " (180, {'pred': 5.389075311820581}),\n",
       " (179, {'pred': 5.270490869522249}),\n",
       " (24, {'pred': 5.129157037090655}),\n",
       " (531, {'pred': 5.07528721362073}),\n",
       " (96, {'pred': 5.04651311545445}),\n",
       " (135, {'pred': 5.023112710379108}),\n",
       " (514, {'pred': 4.959356151295145}),\n",
       " (189, {'pred': 4.83718322231061}),\n",
       " (204, {'pred': 4.8199234273979155}),\n",
       " (109, {'pred': 4.800833023180009}),\n",
       " (1073, {'pred': 4.789246082911456}),\n",
       " (474, {'pred': 4.778009339047167}),\n",
       " (747, {'pred': 4.7772254301035195}),\n",
       " (8, {'pred': 4.77359887135128}),\n",
       " (183, {'pred': 4.75785204952608}),\n",
       " (208, {'pred': 4.674703073381019}),\n",
       " (210, {'pred': 4.660372991311715})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(item_predictions.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user: int, N: int, remove_known_pos: bool = False) -> List[Tuple[int, Dict[str, float]]]:\n",
    "    predictions = get_prediction(user, remove_known_pos=remove_known_pos)\n",
    "    recommendations = []\n",
    "    for item, pred in predictions.items():\n",
    "        add_item = (item, pred)\n",
    "        recommendations.append(add_item)\n",
    "        if len(recommendations) == N:\n",
    "            break\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = get_recommendations(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100, {'pred': 6.7812549925720225}),\n",
       " (238, {'pred': 6.763273617113622}),\n",
       " (56, {'pred': 6.687286904310187}),\n",
       " (7, {'pred': 6.6614164520522605}),\n",
       " (50, {'pred': 6.6134934094960585}),\n",
       " (475, {'pred': 6.346045655925021}),\n",
       " (174, {'pred': 6.219069930457701}),\n",
       " (181, {'pred': 6.202622604233191}),\n",
       " (168, {'pred': 6.0747567806784994}),\n",
       " (98, {'pred': 6.023031945636602})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_items = get_relevant_items(data.test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = relevant_items.keys()\n",
    "prec_at_N = dict.fromkeys(data.users)\n",
    "\n",
    "for user in users:\n",
    "    recommendations = get_recommendations(user, N, remove_known_pos=True)\n",
    "    recommendations = [val[0] for val in recommendations]\n",
    "    hits = np.intersect1d(recommendations,\n",
    "                          relevant_items[user])\n",
    "    prec_at_N[user] = len(hits)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[121, 7, 410, 174, 195, 204, 144, 257, 265, 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18729641693811075"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([val for val in prec_at_N.values() if val is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BAM!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
