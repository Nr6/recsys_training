{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 8: Hybrid Recommender Model using both Collaborative Filtering and Content-based Filtering using a Factorization Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we combine CF and CBF.\n",
    "\n",
    "Therefore, we simply add the one-hot-encoded user and item IDs to the data. Thus, the model is capable of factorizing the similarities in rating and features for rating prediction. This combination is called hybrid as it combines two recommenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfm import pylibfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys_training.data import Dataset, genres\n",
    "from recsys_training.evaluation import get_relevant_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml100k_ratings_filepath = '../data/raw/ml-100k/u.data'\n",
    "ml100k_item_filepath = '../data/raw/ml-100k/u.item'\n",
    "ml100k_user_filepath = '../data/raw/ml-100k/u.user'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(ml100k_ratings_filepath)\n",
    "data.rating_split(seed=42)\n",
    "user_ratings = data.get_user_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_feat = pd.read_csv(ml100k_item_filepath, sep='|', header=None,\n",
    "                        names=['item', 'title', 'release', 'video_release', 'imdb_url']+genres,\n",
    "                        engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = pd.read_csv(ml100k_user_filepath, sep='|', header=None,\n",
    "                        names=['user', 'age', 'gender', 'occupation', 'zip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User and Item Content (Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the following information for items:\n",
    "* release year\n",
    "* genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(val, bounds):\n",
    "    min_max_range = bounds['max']-bounds['min']\n",
    "    return (val-bounds['min'])/min_max_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer the release year\n",
    "idxs = item_feat[item_feat['release'].notnull()].index\n",
    "item_feat.loc[idxs, 'release_year'] = item_feat.loc[idxs, 'release'].str.split('-')\n",
    "item_feat.loc[idxs, 'release_year'] = item_feat.loc[idxs, 'release_year'].apply(lambda val: val[2]).astype(int)\n",
    "\n",
    "# Impute median release year value for the items with missing release year\n",
    "top_year = item_feat.loc[idxs, 'release_year'].astype(int).describe()['50%']\n",
    "idx = item_feat[item_feat['release'].isnull()].index\n",
    "item_feat.loc[idx, 'release_year'] = top_year\n",
    "\n",
    "# Min-max scale the release year\n",
    "item_year_bounds = {'min': item_feat['release_year'].min(),\n",
    "                    'max': item_feat['release_year'].max()}\n",
    "item_feat['release_year'] = item_feat['release_year'].apply(\n",
    "    lambda year: min_max_scale(year, item_year_bounds))\n",
    "\n",
    "# Drop other columns\n",
    "item_feat.drop(['title', 'release', 'video_release', 'imdb_url'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the following information for users:\n",
    "* age\n",
    "* gender\n",
    "* occupation\n",
    "* zip-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max scale the age\n",
    "user_age_bounds = {'min': user_feat['age'].min(),\n",
    "                   'max': user_feat['age'].max()}\n",
    "user_feat['age'] = user_feat['age'].apply(lambda age: min_max_scale(age, user_age_bounds))\n",
    "\n",
    "# Transform gender characters to numerical values (categories)\n",
    "genders = sorted(user_feat['gender'].unique())\n",
    "user_gender_map = dict(zip(genders, range(len(genders))))\n",
    "user_feat['gender'] = user_feat['gender'].map(user_gender_map)\n",
    "\n",
    "# Transform occupation strings to numerical values (categories)\n",
    "occupations = sorted(user_feat['occupation'].unique())\n",
    "user_occupation_map = dict(zip(occupations, range(len(occupations))))\n",
    "user_feat['occupation'] = user_feat['occupation'].map(user_occupation_map)\n",
    "\n",
    "# Transform the zip codes to categories keeping the first three digits and impute for missing\n",
    "idxs = user_feat[~user_feat['zip'].str.isnumeric()].index\n",
    "user_feat.loc[idxs, 'zip'] = '00000'\n",
    "zip_digits_to_cut = 3\n",
    "user_feat['zip'] = user_feat['zip'].apply(lambda val: int(val) // 10 ** zip_digits_to_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we infer profiles by combining item information with rating data for each user to get features that represent the users' preferred genres and film age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_profiler(group):\n",
    "    genre_dist = group[genres].mean()\n",
    "    year_dist = group['release_year'].describe()[['mean', 'std', '50%']]\n",
    "\n",
    "    return pd.concat((genre_dist, year_dist), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profiles(ratings: pd.DataFrame,\n",
    "                      item_feat: pd.DataFrame,\n",
    "                      min_rating: float = 4.0) -> pd.DataFrame:\n",
    "    ratings = ratings[ratings.rating >= min_rating]\n",
    "    ratings = ratings[['user', 'item']]\n",
    "    ratings = ratings.merge(item_feat, on='item', how='left')\n",
    "    ratings.drop(['item'], axis=1, inplace=True)\n",
    "\n",
    "    grouped = ratings.groupby('user')\n",
    "    profiles = grouped.apply(user_profiler).reset_index()\n",
    "    profiles.rename(columns={'50%': 'median'}, inplace=True)\n",
    "    \n",
    "    return profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we join the original user information with their profiles' information and one-hot-encode categorical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = get_user_profiles(data.train_ratings, item_feat)\n",
    "user_feat = user_feat.merge(profiles, on='user', how='left')\n",
    "\n",
    "occupation_1H = pd.get_dummies(user_feat['occupation'], prefix='occupation')\n",
    "zip_1H = pd.get_dummies(user_feat['zip'], prefix='zip')\n",
    "\n",
    "user_feat.drop(['occupation', 'zip', ], axis=1, inplace=True)\n",
    "user_feat = pd.concat([user_feat, occupation_1H, zip_1H], axis=1)\n",
    "\n",
    "user_feat.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the user/item id columns and replace the current dataframe indices with their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat.index = user_feat['user'].values\n",
    "user_feat.drop('user', axis=1, inplace=True)\n",
    "\n",
    "item_feat.index = item_feat['item'].values\n",
    "item_feat.drop('item', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization Machine for a Hybrid Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Steffen Rendle: Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)\n",
    "\n",
    "[pyFM - Factorization Machines in Python](https://github.com/coreylynch/pyFM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Feature Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch content information for all observed user-item rating combinations\n",
    "user_cb_feat_train = user_feat.loc[data.train_ratings.user.values].values\n",
    "user_cb_feat_test = user_feat.loc[data.test_ratings.user.values].values\n",
    "item_cb_feat_train = item_feat.loc[data.train_ratings.item.values].values\n",
    "item_cb_feat_test = item_feat.loc[data.test_ratings.item.values].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Implement additional arrays for user and item IDs and adjust the design matrices `X_train` and `X_test` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_ids(ids: np.array, length):\n",
    "    one_hot_enc = np.zeros((len(ids), length))\n",
    "    one_hot_enc[np.arange(len(ids)), ids] = 1\n",
    "    return one_hot_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract 1 to turn 1-base-indexed into 0-base-indexed IDs for 0-base-indexed array\n",
    "user_cf_feat_train = one_hot_encode_ids(data.train_ratings.user.values-1, data.n_users)\n",
    "user_cf_feat_test = one_hot_encode_ids(data.test_ratings.user.values-1, data.n_users)\n",
    "item_cf_feat_train = one_hot_encode_ids(data.train_ratings.item.values-1, data.n_items)\n",
    "item_cf_feat_test = one_hot_encode_ids(data.test_ratings.item.values-1, data.n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate user and item content information to form design matrices\n",
    "# and convert to sparse matrix in Compressed Sparse Row (CSR) format\n",
    "X_train = np.concatenate((user_cb_feat_train, item_cb_feat_train,\n",
    "                          user_cf_feat_train, item_cf_feat_train), axis=1)\n",
    "X_train = sparse.csr_matrix(X_train)\n",
    "X_test = np.concatenate((user_cb_feat_test, item_cb_feat_test,\n",
    "                         user_cf_feat_test, item_cf_feat_test), axis=1)\n",
    "X_test = sparse.csr_matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity(sparse_arr) -> float:\n",
    "    num_elements = sparse_arr.shape[0]*sparse_arr.shape[1]\n",
    "    num_nonzero_elements = sparse_arr.nnz\n",
    "    density = num_nonzero_elements/num_elements\n",
    "    return 1-density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<80000x2786 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2155351 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903295450466619"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity of Training Data\n",
    "get_sparsity(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x2786 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 538098 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903428212491027"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparsity of Test Data\n",
    "get_sparsity(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Target Matrices for Rating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data.train_ratings.rating.values.astype(float)\n",
    "y_test = data.test_ratings.rating.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Factorization Machine for Rating Prediction as Regressor using pyFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50  # number of full stochastic passes through the training data\n",
    "k = 16\n",
    "random_seed = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.54790\n",
      "-- Epoch 2\n",
      "Training MSE: 0.47424\n",
      "-- Epoch 3\n",
      "Training MSE: 0.44952\n",
      "-- Epoch 4\n",
      "Training MSE: 0.43526\n",
      "-- Epoch 5\n",
      "Training MSE: 0.42663\n",
      "-- Epoch 6\n",
      "Training MSE: 0.41862\n",
      "-- Epoch 7\n",
      "Training MSE: 0.41309\n",
      "-- Epoch 8\n",
      "Training MSE: 0.40803\n",
      "-- Epoch 9\n",
      "Training MSE: 0.40378\n",
      "-- Epoch 10\n",
      "Training MSE: 0.39954\n",
      "-- Epoch 11\n",
      "Training MSE: 0.39576\n",
      "-- Epoch 12\n",
      "Training MSE: 0.39190\n",
      "-- Epoch 13\n",
      "Training MSE: 0.38839\n",
      "-- Epoch 14\n",
      "Training MSE: 0.38523\n",
      "-- Epoch 15\n",
      "Training MSE: 0.38208\n",
      "-- Epoch 16\n",
      "Training MSE: 0.37910\n",
      "-- Epoch 17\n",
      "Training MSE: 0.37622\n",
      "-- Epoch 18\n",
      "Training MSE: 0.37383\n",
      "-- Epoch 19\n",
      "Training MSE: 0.37078\n",
      "-- Epoch 20\n",
      "Training MSE: 0.36818\n",
      "-- Epoch 21\n",
      "Training MSE: 0.36574\n",
      "-- Epoch 22\n",
      "Training MSE: 0.36396\n",
      "-- Epoch 23\n",
      "Training MSE: 0.36161\n",
      "-- Epoch 24\n",
      "Training MSE: 0.35914\n",
      "-- Epoch 25\n",
      "Training MSE: 0.35750\n",
      "-- Epoch 26\n",
      "Training MSE: 0.35517\n",
      "-- Epoch 27\n",
      "Training MSE: 0.35280\n",
      "-- Epoch 28\n",
      "Training MSE: 0.35120\n",
      "-- Epoch 29\n",
      "Training MSE: 0.34908\n",
      "-- Epoch 30\n",
      "Training MSE: 0.34681\n",
      "-- Epoch 31\n",
      "Training MSE: 0.34509\n",
      "-- Epoch 32\n",
      "Training MSE: 0.34333\n",
      "-- Epoch 33\n",
      "Training MSE: 0.34113\n",
      "-- Epoch 34\n",
      "Training MSE: 0.33902\n",
      "-- Epoch 35\n",
      "Training MSE: 0.33758\n",
      "-- Epoch 36\n",
      "Training MSE: 0.33606\n",
      "-- Epoch 37\n",
      "Training MSE: 0.33466\n",
      "-- Epoch 38\n",
      "Training MSE: 0.33289\n",
      "-- Epoch 39\n",
      "Training MSE: 0.33140\n",
      "-- Epoch 40\n",
      "Training MSE: 0.32999\n",
      "-- Epoch 41\n",
      "Training MSE: 0.32854\n",
      "-- Epoch 42\n",
      "Training MSE: 0.32774\n",
      "-- Epoch 43\n",
      "Training MSE: 0.32634\n",
      "-- Epoch 44\n",
      "Training MSE: 0.32485\n",
      "-- Epoch 45\n",
      "Training MSE: 0.32399\n",
      "-- Epoch 46\n",
      "Training MSE: 0.32279\n",
      "-- Epoch 47\n",
      "Training MSE: 0.32166\n",
      "-- Epoch 48\n",
      "Training MSE: 0.32095\n",
      "-- Epoch 49\n",
      "Training MSE: 0.32006\n",
      "-- Epoch 50\n",
      "Training MSE: 0.31912\n"
     ]
    }
   ],
   "source": [
    "fm_hybrid = pylibfm.FM(num_factors=k,\n",
    "                       num_iter=n_epochs,\n",
    "                       verbose=True,\n",
    "                       task=\"regression\",\n",
    "                       initial_learning_rate=0.001,\n",
    "                       learning_rate_schedule=\"optimal\",\n",
    "                       seed=random_seed)\n",
    "fm_hybrid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fm_hybrid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MSE$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8494852442320827"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MAE$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7315855158830586"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(fm: object, user: int, user_feat: pd.DataFrame, item_feat: pd.DataFrame,\n",
    "                   items: np.array = None, remove_known_pos: bool = True) -> Dict[int, Dict[str, float]]:\n",
    "    \n",
    "    if items is None:\n",
    "        if remove_known_pos:\n",
    "            # Predict from unobserved items\n",
    "            known_items = np.array(list(user_ratings[user].keys()))\n",
    "            items = np.setdiff1d(data.items, known_items)\n",
    "        else:\n",
    "            items = np.array(data.items)\n",
    "    if type(items) == np.int64:\n",
    "        items = np.array([items])\n",
    "    \n",
    "    n_items = len(items)\n",
    "    \n",
    "    single_user_cb_feat = user_feat.loc[user].values.reshape(1, -1).repeat(n_items, axis=0)\n",
    "    all_items_cb_feat = item_feat.loc[items].values\n",
    "    \n",
    "    input_data = np.concatenate((single_user_cb_feat, all_items_cb_feat), axis=1)\n",
    "    input_data = sparse.csr_matrix(input_data)\n",
    "    \n",
    "    preds = fm.predict(input_data)\n",
    "    sorting = np.argsort(preds)[::-1]\n",
    "    \n",
    "    preds = {item: {'pred': pred} for item, pred in\n",
    "             zip(items[sorting], preds[sorting])}\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(611, {'pred': 4.128607158293412}),\n",
       " (656, {'pred': 3.980267508437738}),\n",
       " (1122, {'pred': 3.843400986550824}),\n",
       " (484, {'pred': 3.827364054040706}),\n",
       " (1542, {'pred': 3.8189397788509907}),\n",
       " (1064, {'pred': 3.8046569464331306}),\n",
       " (483, {'pred': 3.804042567831896}),\n",
       " (617, {'pred': 3.76432842353529}),\n",
       " (525, {'pred': 3.7473190553330658}),\n",
       " (1453, {'pred': 3.7308344658756196})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = get_prediction(fm_hybrid, 1, user_feat, item_feat)\n",
    "list(predictions.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(fm_cb: object,\n",
    "                        user: int,\n",
    "                        N: int,\n",
    "                        user_feat: pd.DataFrame,\n",
    "                        item_feat: pd.DataFrame,\n",
    "                        remove_known_pos: bool = True) -> List[Tuple[int, Dict[str, float]]]:\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    predictions = get_prediction(fm_cb, user, user_feat, item_feat,\n",
    "                                 remove_known_pos=remove_known_pos)\n",
    "\n",
    "    for item, pred in predictions.items():\n",
    "        add_item = (item, pred)\n",
    "        recommendations.append(add_item)\n",
    "        if len(recommendations) == N:\n",
    "            break\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(611, {'pred': 4.128607158293412}),\n",
       " (656, {'pred': 3.980267508437738}),\n",
       " (1122, {'pred': 3.843400986550824}),\n",
       " (484, {'pred': 3.827364054040706}),\n",
       " (1542, {'pred': 3.8189397788509907}),\n",
       " (1064, {'pred': 3.8046569464331306}),\n",
       " (483, {'pred': 3.804042567831896}),\n",
       " (617, {'pred': 3.76432842353529}),\n",
       " (525, {'pred': 3.7473190553330658}),\n",
       " (1453, {'pred': 3.7308344658756196})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(fm_hybrid, 1, N=10, user_feat=user_feat, item_feat=item_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_items = get_relevant_items(data.test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = relevant_items.keys()\n",
    "prec_at_N = dict.fromkeys(data.users)\n",
    "\n",
    "for user in users:\n",
    "    recommendations = get_recommendations(fm_hybrid, user, N,\n",
    "                                          user_feat=user_feat, item_feat=item_feat)\n",
    "    recommendations = [val[0] for val in recommendations]\n",
    "    hits = np.intersect1d(recommendations,\n",
    "                          relevant_items[user])\n",
    "    prec_at_N[user] = len(hits)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[133, 483, 1124, 1542, 1122, 17, 1299, 498, 617, 1204]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0174468085106383"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([val for val in prec_at_N.values() if val is not None])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
